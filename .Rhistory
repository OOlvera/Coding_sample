## Set paths
## Change this when needed
path_raw <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/raw_data"
path_clean <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/clean_data"
path_plot <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/plots"
## From Data source 4
## Objective: Text processing of the primary care centers in Mexico
## Source: Mexican National Institute of Statistics
nlp_data <- read.csv(file.path(path_clean,"nlp_data.csv"))
## Delete stop words and additional common words not useful for the analysis. The words are in Spanish
custom_stop_words <- data.frame(word = stopwords("es"), lexicon = "custom")
uni_sw <- data.frame(word = c("consultorio","medico","nombre", "medicina", "médico", "consultorios", "medica", "consultorios"))
nlp_words <- nlp_data %>%
unnest_tokens(word, nom_estab) %>%
anti_join(custom_stop_words) %>%
anti_join(uni_sw, by = "word") %>%
select(word) %>%
count(word, sort = TRUE) %>%
ungroup()
## Visualizations of most common names/words for private primary care centers
## 1. WordCloud
## Source: https://richpauloo.github.io/2017-12-29-Using-tidytext-to-make-word-clouds/
## The WordCloud shows that most of the primary care centers are located in pharmacies ("farmacia")
## This is important for healthcare policies
pal <- brewer.pal(8,"Dark2")
png(file.path(path_plot,"wordcloud_plot.png"))
nlp_words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 40, colors=pal))
dev.off()
install.packages("wordcloud")
library(wordcloud)
pal <- brewer.pal(8,"Dark2")
png(file.path(path_plot,"wordcloud_plot.png"))
nlp_words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 40, colors=pal))
dev.off()
primary_care <- nlp_data %>%
group_by(entidad) %>%
summarise(total_pc = n())
primary_care$ADM1_ES <- str_to_title(primary_care$entidad)
primary_care$ADM1_ES <-str_trim(primary_care$ADM1_ES, side = c("right"))
primary_care <- primary_care %>%
mutate(ADM1_ES = str_replace(ADM1_ES, "Veracruz De Ignacio De La Llave", "Veracruz de Ignacio de la Llave"),
ADM1_ES = str_replace(ADM1_ES, "Michoacán De Ocampo", "Michoacán de Ocampo"),
ADM1_ES = str_replace(ADM1_ES, "Coahuila De Zaragoza", "Coahuila de Zaragoza"),
ADM1_ES = str_replace(ADM1_ES, "Ciudad De México", "Distrito Federal"),
ADM1_ES = str_replace(ADM1_ES, "Querétaro", "Querétaro de Arteaga"))
mexico_shape <- st_read(file.path(path_raw, "mexican_states_shapefile.shp"), options = "ENCODING=UTF-8")
install.packages("sf")
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
#install.packages("wordcloud")
library(wordcloud)
#install.packages("sf")
library(sf)
library(rnaturalearth)
library(mxmaps)
library(syuzhet)
#install.packages("stopwords")
library(stopwords)
library(dplyr)
#install.packages("RColorBrewer")
library(RColorBrewer)
#devtools::install_github("diegovalle/mxmaps")
## Set paths
## Change this when needed
path_raw <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/raw_data"
path_clean <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/clean_data"
path_plot <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/plots"
## From Data source 4
## Objective: Text processing of the primary care centers in Mexico
## Source: Mexican National Institute of Statistics
nlp_data <- read.csv(file.path(path_clean,"nlp_data.csv"))
## Delete stop words and additional common words not useful for the analysis. The words are in Spanish
custom_stop_words <- data.frame(word = stopwords("es"), lexicon = "custom")
uni_sw <- data.frame(word = c("consultorio","medico","nombre", "medicina", "médico", "consultorios", "medica", "consultorios"))
nlp_words <- nlp_data %>%
unnest_tokens(word, nom_estab) %>%
anti_join(custom_stop_words) %>%
anti_join(uni_sw, by = "word") %>%
select(word) %>%
count(word, sort = TRUE) %>%
ungroup()
## Visualizations of most common names/words for private primary care centers
## 1. WordCloud
## Source: https://richpauloo.github.io/2017-12-29-Using-tidytext-to-make-word-clouds/
## The WordCloud shows that most of the primary care centers are located in pharmacies ("farmacia")
## This is important for healthcare policies
pal <- brewer.pal(8,"Dark2")
png(file.path(path_plot,"wordcloud_plot.png"))
nlp_words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 40, colors=pal))
dev.off()
## 2. Maps
## Data wrangling based on the NLP data
primary_care <- nlp_data %>%
group_by(entidad) %>%
summarise(total_pc = n())
primary_care$ADM1_ES <- str_to_title(primary_care$entidad)
primary_care$ADM1_ES <-str_trim(primary_care$ADM1_ES, side = c("right"))
primary_care <- primary_care %>%
mutate(ADM1_ES = str_replace(ADM1_ES, "Veracruz De Ignacio De La Llave", "Veracruz de Ignacio de la Llave"),
ADM1_ES = str_replace(ADM1_ES, "Michoacán De Ocampo", "Michoacán de Ocampo"),
ADM1_ES = str_replace(ADM1_ES, "Coahuila De Zaragoza", "Coahuila de Zaragoza"),
ADM1_ES = str_replace(ADM1_ES, "Ciudad De México", "Distrito Federal"),
ADM1_ES = str_replace(ADM1_ES, "Querétaro", "Querétaro de Arteaga"))
mexico_shape <- st_read(file.path(path_raw, "mexican_states_shapefile.shp"), options = "ENCODING=UTF-8")
library(sf)
install.packages("sf")
library(sf)
install.packages("units")
library(sf)
library(units)
install.packages(c("BH", "Rcpp", "cpp11", "digest", "dplyr", "glue", "lifecycle", "magrittr", "R6", "rlang", "tibble", "tidyselect", "vctrs"))
library(sf)
install.packages(c("mnormt", "statmod", "ucminf", "chron", "gridExtra", "Formula", "nlme", "latticeExtra", "zoo"))
library(sf)
install.packages('sf', dependencies = TRUE)
remove.packages('sf')
install.packages('sf')
library(sf)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
#install.packages("wordcloud")
library(wordcloud)
#install.packages("sf")
library(sf)
library(rnaturalearth)
library(mxmaps)
library(syuzhet)
#install.packages("stopwords")
library(stopwords)
library(dplyr)
#install.packages("RColorBrewer")
library(RColorBrewer)
devtools::install_github("diegovalle/mxmaps")
librayr(devtools)
library(devtools)
install.packages('devtools')
library(devtools)
devtools::install_github("diegovalle/mxmaps")
library(mxmaps)
path_raw <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/raw_data"
path_clean <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/clean_data"
path_plot <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/plots"
## From Data source 4
## Objective: Text processing of the primary care centers in Mexico
## Source: Mexican National Institute of Statistics
nlp_data <- read.csv(file.path(path_clean,"nlp_data.csv"))
## Delete stop words and additional common words not useful for the analysis. The words are in Spanish
custom_stop_words <- data.frame(word = stopwords("es"), lexicon = "custom")
uni_sw <- data.frame(word = c("consultorio","medico","nombre", "medicina", "médico", "consultorios", "medica", "consultorios"))
nlp_words <- nlp_data %>%
unnest_tokens(word, nom_estab) %>%
anti_join(custom_stop_words) %>%
anti_join(uni_sw, by = "word") %>%
select(word) %>%
count(word, sort = TRUE) %>%
ungroup()
## Visualizations of most common names/words for private primary care centers
## 1. WordCloud
## Source: https://richpauloo.github.io/2017-12-29-Using-tidytext-to-make-word-clouds/
## The WordCloud shows that most of the primary care centers are located in pharmacies ("farmacia")
## This is important for healthcare policies
pal <- brewer.pal(8,"Dark2")
png(file.path(path_plot,"wordcloud_plot.png"))
nlp_words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 40, colors=pal))
dev.off()
primary_care <- nlp_data %>%
group_by(entidad) %>%
summarise(total_pc = n())
primary_care$ADM1_ES <- str_to_title(primary_care$entidad)
primary_care$ADM1_ES <-str_trim(primary_care$ADM1_ES, side = c("right"))
primary_care <- primary_care %>%
mutate(ADM1_ES = str_replace(ADM1_ES, "Veracruz De Ignacio De La Llave", "Veracruz de Ignacio de la Llave"),
ADM1_ES = str_replace(ADM1_ES, "Michoacán De Ocampo", "Michoacán de Ocampo"),
ADM1_ES = str_replace(ADM1_ES, "Coahuila De Zaragoza", "Coahuila de Zaragoza"),
ADM1_ES = str_replace(ADM1_ES, "Ciudad De México", "Distrito Federal"),
ADM1_ES = str_replace(ADM1_ES, "Querétaro", "Querétaro de Arteaga"))
## Map 1: Total number of private primary care centers by state (absolute numbers)
mexico_shape <- st_read(file.path(path_raw, "mexican_states_shapefile.shp"), options = "ENCODING=UTF-8")
primary_care_final<- left_join(mexico_shape, primary_care, by='ADM1_ES')
map_format <- scale_fill_gradientn(colours = hcl.colors(3, "GnBu", rev = TRUE),n.breaks = 4)
png(file.path(path_plot,"map_1.png"))
ggplot() +
geom_sf(data = primary_care_final, aes(fill = total_pc)) +
map_format +
labs(title="Total private primary care centers",
fill = "Total") +
theme_void()
dev.off()
## Map 2: Total number of private primary care centers by state (controlled by population)
## population data from the library mxmaps
pop_data <- df_mxstate_2020 %>%
mutate(state_name_official = str_replace(state_name_official, "Querétaro", "Querétaro de Arteaga"),
state_name_official = str_replace(state_name_official, "Ciudad de México", "Distrito Federal"))
pop_data$ADM1_ES <- pop_data$state_name_official
primary_care_final<- primary_care_final %>%
left_join(pop_data, by='ADM1_ES') %>%
mutate(total_pc_r = (total_pc/pop)* 100)
png(file.path(path_plot,"map_2.png"))
ggplot() +
geom_sf(data = primary_care_final, aes(fill = total_pc_r)) +
map_format +
labs(title="Private primary care centers (relative to population)",
fill = "Percentage") +
theme_void()
dev.off()
## From Data source 5
## Objective: NRC Sentiment Analysis of Mexican news about out-of-pocket
news_nlp <- read.csv("news_nlp.csv")
# NRC as the chosen sentiment package
sentiment_nrc <- get_sentiments("nrc") %>%
rename(nrc = sentiment)
text_df <- as.character(news_nlp$title)
text_df <- tibble(text = text_df)
text_df <- text_df %>%
unnest_tokens(word_tokens, text, token="words") %>%
anti_join(stop_words, by = c("word_tokens" = "word")) %>%
left_join(sentiment_nrc, by = c("word_tokens" = "word")) %>%
filter(nrc != "positive" & nrc != "negative")
## Plotting the NRC results
png(file.path(path_plot,"NRC_plot.png"))
ggplot(data = filter(text_df, !is.na(nrc))) +
geom_histogram(aes(nrc), stat = "count", fill="Navy") +
scale_x_discrete(guide = guide_axis(angle = 45)) +
labs(title = "Overall sentiment analysis: Mexican news about out-of-pocket",
subtitle = "NRC method") +
theme_minimal()
dev.off()
news_nlp <- read.csv("news_nlp.csv")
news_nlp <- read.csv(file.path(path_clean,"news_nlp.csv"))
sentiment_nrc <- get_sentiments("nrc") %>%
rename(nrc = sentiment)
text_df <- as.character(news_nlp$title)
text_df <- tibble(text = text_df)
sentiment_nrc <- get_sentiments("nrc") %>%
rename(nrc = sentiment)
install.packages("textdata")
library(textdata)
sentiment_nrc <- get_sentiments("nrc") %>%
rename(nrc = sentiment)
text_df <- as.character(news_nlp$title)
text_df <- tibble(text = text_df)
text_df <- text_df %>%
unnest_tokens(word_tokens, text, token="words") %>%
anti_join(stop_words, by = c("word_tokens" = "word")) %>%
left_join(sentiment_nrc, by = c("word_tokens" = "word")) %>%
filter(nrc != "positive" & nrc != "negative")
## Plotting the NRC results
png(file.path(path_plot,"NRC_plot.png"))
ggplot(data = filter(text_df, !is.na(nrc))) +
geom_histogram(aes(nrc), stat = "count", fill="Navy") +
scale_x_discrete(guide = guide_axis(angle = 45)) +
labs(title = "Overall sentiment analysis: Mexican news about out-of-pocket",
subtitle = "NRC method") +
theme_minimal()
dev.off()
## Text Processing Analysis
## Author: Laura Olivia Olvera
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
#install.packages("wordcloud")
library(wordcloud)
#install.packages("sf")
library(sf)
library(rnaturalearth)
library(devtools)
#devtools::install_github("diegovalle/mxmaps")
library(mxmaps)
library(syuzhet)
#install.packages("stopwords")
library(stopwords)
library(dplyr)
#install.packages("RColorBrewer")
library(RColorBrewer)
#install.packages("textdata")
library(textdata)
## Set paths
## Change this when needed
path_raw <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/raw_data"
path_clean <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/clean_data"
path_plot <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/plots"
## From Data source 4
## Objective: Text processing of the primary care centers in Mexico
## Source: Mexican National Institute of Statistics
nlp_data <- read.csv(file.path(path_clean,"nlp_data.csv"))
## Delete stop words and additional common words not useful for the analysis. The words are in Spanish
custom_stop_words <- data.frame(word = stopwords("es"), lexicon = "custom")
uni_sw <- data.frame(word = c("consultorio","medico","nombre", "medicina", "médico", "consultorios", "medica", "consultorios"))
nlp_words <- nlp_data %>%
unnest_tokens(word, nom_estab) %>%
anti_join(custom_stop_words) %>%
anti_join(uni_sw, by = "word") %>%
select(word) %>%
count(word, sort = TRUE) %>%
ungroup()
## Visualizations of most common names/words for private primary care centers
## 1. WordCloud
## Source: https://richpauloo.github.io/2017-12-29-Using-tidytext-to-make-word-clouds/
## The WordCloud shows that most of the primary care centers are located in pharmacies ("farmacia")
## This is important for healthcare policies
pal <- brewer.pal(8,"Dark2")
png(file.path(path_plot,"wordcloud_plot.png"))
nlp_words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 40, colors=pal))
dev.off()
## 2. Maps
## Data wrangling based on the NLP data
primary_care <- nlp_data %>%
group_by(entidad) %>%
summarise(total_pc = n())
primary_care$ADM1_ES <- str_to_title(primary_care$entidad)
primary_care$ADM1_ES <-str_trim(primary_care$ADM1_ES, side = c("right"))
primary_care <- primary_care %>%
mutate(ADM1_ES = str_replace(ADM1_ES, "Veracruz De Ignacio De La Llave", "Veracruz de Ignacio de la Llave"),
ADM1_ES = str_replace(ADM1_ES, "Michoacán De Ocampo", "Michoacán de Ocampo"),
ADM1_ES = str_replace(ADM1_ES, "Coahuila De Zaragoza", "Coahuila de Zaragoza"),
ADM1_ES = str_replace(ADM1_ES, "Ciudad De México", "Distrito Federal"),
ADM1_ES = str_replace(ADM1_ES, "Querétaro", "Querétaro de Arteaga"))
## Map 1: Total number of private primary care centers by state (absolute numbers)
mexico_shape <- st_read(file.path(path_raw, "mexican_states_shapefile.shp"), options = "ENCODING=UTF-8")
primary_care_final<- left_join(mexico_shape, primary_care, by='ADM1_ES')
map_format <- scale_fill_gradientn(colours = hcl.colors(3, "GnBu", rev = TRUE),n.breaks = 4)
png(file.path(path_plot,"map_1.png"))
ggplot() +
geom_sf(data = primary_care_final, aes(fill = total_pc)) +
map_format +
labs(title="Total private primary care centers",
fill = "Total") +
theme_void()
dev.off()
## Map 2: Total number of private primary care centers by state (controlled by population)
## population data from the library mxmaps
pop_data <- df_mxstate_2020 %>%
mutate(state_name_official = str_replace(state_name_official, "Querétaro", "Querétaro de Arteaga"),
state_name_official = str_replace(state_name_official, "Ciudad de México", "Distrito Federal"))
pop_data$ADM1_ES <- pop_data$state_name_official
primary_care_final<- primary_care_final %>%
left_join(pop_data, by='ADM1_ES') %>%
mutate(total_pc_r = (total_pc/pop)* 100)
png(file.path(path_plot,"map_2.png"))
ggplot() +
geom_sf(data = primary_care_final, aes(fill = total_pc_r)) +
map_format +
labs(title="Private primary care centers (relative to population)",
fill = "Percentage") +
theme_void()
dev.off()
## From Data source 5
## Objective: NRC Sentiment Analysis of Mexican news about out-of-pocket
news_nlp <- read.csv(file.path(path_clean,"news_nlp.csv"))
# NRC as the chosen sentiment package
sentiment_nrc <- get_sentiments("nrc") %>%
rename(nrc = sentiment)
text_df <- as.character(news_nlp$title)
text_df <- tibble(text = text_df)
text_df <- text_df %>%
unnest_tokens(word_tokens, text, token="words") %>%
anti_join(stop_words, by = c("word_tokens" = "word")) %>%
left_join(sentiment_nrc, by = c("word_tokens" = "word")) %>%
filter(nrc != "positive" & nrc != "negative")
## Plotting the NRC results
png(file.path(path_plot,"NRC_plot.png"))
ggplot(data = filter(text_df, !is.na(nrc))) +
geom_histogram(aes(nrc), stat = "count", fill="Navy") +
scale_x_discrete(guide = guide_axis(angle = 45)) +
labs(title = "Overall sentiment analysis: Mexican news about out-of-pocket",
subtitle = "NRC method") +
theme_minimal()
dev.off()
## Data visualizations
## Author: Laura Olivia Olvera
library(tidyverse)
library(ggplot2)
library(readxl)
library(readr)
library(dplyr)
library(magrittr)
library(tidyr)
## Set paths
## Change this when needed
path_raw <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/raw_data"
path_clean <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/clean_data"
plot_format <-  theme(panel.background = element_blank(),
plot.title = element_text(size=15, vjust = 2.5, hjust = 0.5),
legend.title = element_blank(),
legend.position="none",
axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.title.x = element_text(size = 11, margin = margin(r = 15)),
axis.title.y = element_text(size = 11, margin = margin(r = 15)),
axis.line = element_line(colour = "black", size = .5),
plot.caption=element_text(size=9, hjust=0))
## Out-of-pocket
df_final <- read.csv(file.path(path_clean,"df_final.csv"))
df_final <- transform(df_final, diabetes = as.numeric(diabetes))
out_of_pocket_plot <- df_final %>%
filter(date==2019) %>%
drop_na(out_of_pocket) %>%
ggplot(aes(x = reorder(country, out_of_pocket), y = out_of_pocket, fill = ifelse(country == "Mexico", "Highlighted", "Normal"))) +
geom_bar(position = "dodge", stat = "identity",
width = 0.7) +
labs(title = "Out-of-pocket expenditure (2019), Latin America and the Caribbean",
y = "Percentage (%)",
x = "",
caption = "Source: World Bank")  +
plot_format +
coord_flip()
png(file.path(path_plot,"out_of_pocket_plot.png"))
out_of_pocket_plot
dev.off()
## Data visualizations
## Author: Laura Olivia Olvera
library(tidyverse)
library(ggplot2)
library(readxl)
library(readr)
library(dplyr)
library(magrittr)
library(tidyr)
## Set paths
## Change this when needed
path_raw <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/raw_data"
path_clean <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/clean_data"
path_plot <- "C:/Users/olivi/Box/FALL 2022/Data and Programming/Coding_sample/plots"
plot_format <-  theme(panel.background = element_blank(),
plot.title = element_text(size=15, vjust = 2.5, hjust = 0.5),
legend.title = element_blank(),
legend.position="none",
axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.title.x = element_text(size = 11, margin = margin(r = 15)),
axis.title.y = element_text(size = 11, margin = margin(r = 15)),
axis.line = element_line(colour = "black", size = .5),
plot.caption=element_text(size=9, hjust=0))
## Out-of-pocket
df_final <- read.csv(file.path(path_clean,"df_final.csv"))
df_final <- transform(df_final, diabetes = as.numeric(diabetes))
out_of_pocket_plot <- df_final %>%
filter(date==2019) %>%
drop_na(out_of_pocket) %>%
ggplot(aes(x = reorder(country, out_of_pocket), y = out_of_pocket, fill = ifelse(country == "Mexico", "Highlighted", "Normal"))) +
geom_bar(position = "dodge", stat = "identity",
width = 0.7) +
labs(title = "Out-of-pocket expenditure (2019), Latin America and the Caribbean",
y = "Percentage (%)",
x = "",
caption = "Source: World Bank")  +
plot_format +
coord_flip()
png(file.path(path_plot,"out_of_pocket_plot.png"))
out_of_pocket_plot
dev.off()
## Life expectancy
life_expectancy_plot <- df_final %>%
filter(date==2019) %>%
drop_na(out_of_pocket) %>%
ggplot(aes(x = life_exp, y = out_of_pocket)) +
geom_point() +
geom_text(hjust = 0, nudge_x = 0.1, size = 2, aes(label = iso3c)) +
geom_smooth(method = lm, color = "darkred") +
#scale_fill_continuous(low='yellow', high='#de2d26') +
labs(title = "Relation between life expectancy and out-of-pocket expenditure (2019) in Latin America and the Caribbean",
y = "Percentage of out-of-pocket expenditure",
x = "Life expectancy",
caption = "Source: World Bank")  +
plot_format
png(file.path(path_plot,"life_expectancy_plot.png"))
life_expectancy_plot
dev.off()
## Diabetes
diabetes_plot <- df_final %>%
filter(date==2019) %>%
drop_na(out_of_pocket) %>%
drop_na(diabetes) %>%
ggplot(aes(x = diabetes, y = out_of_pocket)) +
geom_point() +
geom_text(hjust = 0, nudge_x = 0.1, size = 2, aes(label = iso3c)) +
geom_smooth(method = lm, color = "darkred") +
labs(title = "Diabetes and out-of-pocket expenditure (2019) in Latin America and the Caribbean",
y = "Percentage of out-of-pocket expenditure",
x = "Percentage of population with diabetes",
caption = "Source: World Bank")  +
plot_format
png(file.path(path_plot,"diabetes_plot.png"))
diabetes_plot
dev.off()
## Health expenditure in Mexico
health_exp_mex <- read.csv(file.path(path_clean,"health_exp_mex.csv"))
health_exp_mex_plot <- ggplot(health_exp_mex, aes(y = expenditure, x = date)) +
geom_col(aes(fill = exp_type1), width = 0.7)+
geom_text(aes(label = expenditure, group = exp_type1), color = "white", position = position_stack(vjust = 0.5), size = 4) +
labs(title = "Out-of-pocket expenditure in Mexico by dimensions",
y = "Percentage",
x = "",
caption = "Source: National Institute of Statistics and Geography (INEGI)")  +
scale_fill_manual(values = c("#003f5c", "#444e86","#955196","#dd5182","#ff6e54")) +
plot_format +
theme(legend.title = element_blank(),
legend.position="right")
png(file.path(path_plot,"health_exp_mex_plot.png"))
health_exp_mex_plot
dev.off()
library(shiny); runApp('5_Shiny_App.R')
